{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "messages=Queue()\n",
    "recordings=Queue()\n",
    "channels=1\n",
    "frame_rate=16000\n",
    "record_seconds=20\n",
    "audio_format=pyaudio.paInt16\n",
    "sample_size=2\n",
    "\n",
    "def record_microphone(chunk=12045):\n",
    "    p=pyaudio.PyAudio()\n",
    "    stream=p.open(format=audio_format,\n",
    "                  channels=channels,\n",
    "                  rate=frame_rate,\n",
    "                  input=True,\n",
    "                  input_device_index=2,\n",
    "                  frames_per_buffer=chunk)\n",
    "    frames=[]\n",
    "    while not messages.empty():\n",
    "        data=stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        if len(frames)>=(frame_rate*record_seconds)/chunk:\n",
    "            recordings.put(frames.copy())\n",
    "            frames=[]\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Chunks:\n",
      "Chunk 1: 'The quick brown fox jumps over the lazy dog. This is the first sentence.'\n",
      "Chunk 2: 'The lazy dog barks loudly at the fox. This is the second sentence, and it's quite important.'\n",
      "Chunk 3: 'Jumping foxes and barking dogs are common sights in the countryside.'\n",
      "Chunk 4: 'Countryside life is peaceful and quiet, unlike the busy city.'\n",
      "Chunk 5: 'The city never sleeps, with its constant noise and activity.'\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords per Chunk:\n",
      "Chunk 1: ['quick', 'brown', 'fox', 'jumps', 'lazy']\n",
      "Chunk 2: ['lazy', 'dog', 'barks', 'loudly', 'fox']\n",
      "Chunk 3: ['jumping', 'foxes', 'barking', 'dogs', 'common']\n",
      "Chunk 4: ['countryside', 'life', 'peaceful', 'quiet', 'unlike']\n",
      "Chunk 5: ['city', 'never', 'sleeps', 'constant', 'noise']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract_keywords_from_chunks(chunks, keyword_extractor_model=\"bert-base-uncased\"):\n",
    "\n",
    "    keyword_extraction_pipeline = pipeline(\"feature-extraction\", model=keyword_extractor_model)\n",
    "    chunk_keywords = {}\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():  # Process only non-empty chunks\n",
    "            try:\n",
    "                embeddings = keyword_extraction_pipeline(chunk)\n",
    "                from collections import Counter\n",
    "                import nltk\n",
    "                from nltk.corpus import stopwords\n",
    "                from nltk.tokenize import word_tokenize\n",
    "\n",
    "                nltk.download('punkt', quiet=True)\n",
    "                nltk.download('stopwords', quiet=True)\n",
    "\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                word_tokens = word_tokenize(chunk.lower())\n",
    "                filtered_words = [w for w in word_tokens if not w in stop_words and w.isalnum()]\n",
    "                word_counts = Counter(filtered_words)\n",
    "                top_n = min(5, len(word_counts))  # Extract top 5 or fewer keywords\n",
    "                keywords = [word for word, count in word_counts.most_common(top_n)]\n",
    "\n",
    "                chunk_keywords[f\"Chunk {i+1}\"] = keywords\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {i+1}: {e}\")\n",
    "                chunk_keywords[f\"Chunk {i+1}\"] = []\n",
    "        else:\n",
    "            chunk_keywords[f\"Chunk {i+1}\"] = []\n",
    "\n",
    "    return chunk_keywords\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        # Sample chunkified data (replace with your actual chunks)\n",
    "    text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog. This is the first sentence.\n",
    "    The lazy dog barks loudly at the fox. This is the second sentence, and it's quite important.\n",
    "    Jumping foxes and barking dogs are common sights in the countryside.\n",
    "    Countryside life is peaceful and quiet, unlike the busy city.\n",
    "    The city never sleeps, with its constant noise and activity.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "# Initialize recognizer\n",
    "    print(\"Generated Chunks:\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Extract keywords for each chunk\n",
    "    keywords_per_chunk = extract_keywords_from_chunks(chunks)\n",
    "\n",
    "    print(\"Keywords per Chunk:\")\n",
    "    for chunk_id, keywords in keywords_per_chunk.items():\n",
    "        print(f\"{chunk_id}: {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for 'skeleton danger' saved to 'downloaded_images/skeleton_danger.jpg'\n",
      "Image successfully scraped and saved to: downloaded_images/skeleton_danger.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def scrape_image_from_web(keyword, output_dir=\"downloaded_images\"):\n",
    "    \"\"\"\n",
    "    Scrapes the first image from a Google Images search for a given keyword\n",
    "    and saves it to the specified output directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    search_url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "\n",
    "        if not img_tags:\n",
    "            print(\"No images found on the page.\")\n",
    "            return None\n",
    "\n",
    "        # The first image tag often contains the actual image\n",
    "        img_url = img_tags[1].get('src')  # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "        if not img_url or img_url.startswith('data:image'):\n",
    "            img_url = img_tags[1].get('data-src') # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "\n",
    "        if not img_url:\n",
    "          print(\"Could not find the image URL.\")\n",
    "          return None\n",
    "\n",
    "\n",
    "        # Download the image\n",
    "        try:\n",
    "            img_response = requests.get(img_url, stream=True, timeout=10)\n",
    "            img_response.raise_for_status()\n",
    "            image = Image.open(BytesIO(img_response.content))\n",
    "\n",
    "            # Save the image\n",
    "            filename = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            image.save(filepath, \"JPEG\")\n",
    "\n",
    "            print(f\"Image for '{keyword}' saved to '{filepath}'\")\n",
    "            return filepath\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading the image: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "          print(f\"Error processing the image {e}\")\n",
    "          return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during the search request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "      print(f\"Other error occurred: {e}\")\n",
    "      return None\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = \"skeleton danger\"  # Replace with your desired keyword\n",
    "    image_path = scrape_image_from_web(keyword)\n",
    "\n",
    "    if image_path:\n",
    "        print(f\"Image successfully scraped and saved to: {image_path}\")\n",
    "    else:\n",
    "        print(\"Failed to scrape and save the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk 1: 'There is a heart. The heart has 4 parts. Heart has...'\n",
      "  Extracted Nouns: ['heart', 'parts', 'ventricles']\n",
      "\n",
      "Chunk 2: 'is the most important part of the...'\n",
      "  Extracted Nouns: ['part']\n",
      "\n",
      "Chunk 3: 'humman body. If heart stops everything else stops....'\n",
      "  Extracted Nouns: ['humman', 'body', 'heart']\n",
      "\n",
      "Starting image search for keywords: ['heart', 'parts', 'ventricles', 'part', 'humman', 'body']\n",
      "\n",
      "Searching images for: heart\n",
      "Image for 'heart' saved to 'extracted_images/heart.jpg'\n",
      "\n",
      "Searching images for: parts\n",
      "Image for 'parts' saved to 'extracted_images/parts.jpg'\n",
      "\n",
      "Searching images for: ventricles\n",
      "Image for 'ventricles' saved to 'extracted_images/ventricles.jpg'\n",
      "\n",
      "Searching images for: part\n",
      "Image for 'part' saved to 'extracted_images/part.jpg'\n",
      "\n",
      "Searching images for: humman\n",
      "Image for 'humman' saved to 'extracted_images/humman.jpg'\n",
      "\n",
      "Searching images for: body\n",
      "Image for 'body' saved to 'extracted_images/body.jpg'\n",
      "\n",
      "Image extraction process completed.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "SEARCH_API_KEY = \"YOUR_GOOGLE_API_KEY\"  # Replace with your Google Custom Search API key\n",
    "SEARCH_ENGINE_ID = \"YOUR_SEARCH_ENGINE_ID\"  # Replace with your Custom Search Engine ID\n",
    "\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    \"\"\"Extracts top N noun keywords using POS tagging\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    # Filter nouns (NN, NNS, NNP, NNPS)\n",
    "    nouns = [word for (word, tag) in pos_tags \n",
    "            if tag in ['NN', 'NNS', 'NNP', 'NNPS'] \n",
    "            and word.isalnum() \n",
    "            and word not in stop_words]\n",
    "    \n",
    "    return [word for word, count in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "def scrape_image_from_web(keyword, output_dir=\"downloaded_images\"):\n",
    "    \"\"\"\n",
    "    Scrapes the first image from a Google Images search for a given keyword\n",
    "    and saves it to the specified output directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    search_url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "\n",
    "        if not img_tags:\n",
    "            print(\"No images found on the page.\")\n",
    "            return None\n",
    "\n",
    "        # The first image tag often contains the actual image\n",
    "        img_url = img_tags[1].get('src')  # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "        if not img_url or img_url.startswith('data:image'):\n",
    "            img_url = img_tags[1].get('data-src') # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "\n",
    "        if not img_url:\n",
    "          print(\"Could not find the image URL.\")\n",
    "          return None\n",
    "\n",
    "\n",
    "        # Download the image\n",
    "        try:\n",
    "            img_response = requests.get(img_url, stream=True, timeout=10)\n",
    "            img_response.raise_for_status()\n",
    "            image = Image.open(BytesIO(img_response.content))\n",
    "\n",
    "            # Save the image\n",
    "            filename = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            image.save(filepath, \"JPEG\")\n",
    "\n",
    "            print(f\"Image for '{keyword}' saved to '{filepath}'\")\n",
    "            return filepath\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading the image: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "          print(f\"Error processing the image {e}\")\n",
    "          return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during the search request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "      print(f\"Other error occurred: {e}\")\n",
    "      return None\n",
    "\n",
    "\n",
    "def process_chunks(chunks, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Processes text chunks to extract nouns and download related images\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_keywords = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_nouns(chunk)\n",
    "            print(f\"\\nChunk {i+1}: '{chunk[:50]}...'\")\n",
    "            print(f\"  Extracted Nouns: {keywords}\")\n",
    "            all_keywords.extend(keywords)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_keywords = [k for k in all_keywords if not (k in seen or seen.add(k))]\n",
    "    \n",
    "    print(\"\\nStarting image search for keywords:\", unique_keywords)\n",
    "    \n",
    "    for keyword in unique_keywords:\n",
    "        print(f\"\\nSearching images for: {keyword}\")\n",
    "        scrape_image_from_web(keyword, output_dir) # Using the image scraping function\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample text\n",
    "    text = \"\"\"There is a heart. The heart has 4 parts. Heart has ventricles and arteries that supply blood in and out of the heart.It is the most important part of the \n",
    "    humman body. If heart stops everything else stops.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Process chunks and download images\n",
    "    process_chunks(chunks)\n",
    "    print(\"\\nImage extraction process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Chunk 1: 'There is a heart. The heart has 4 parts. Heart has...'\n",
      "Extracted Keywords: ['heart', 'parts', 'ventricles']\n",
      "Image for 'heart' saved to 'extracted_images/heart.jpg'.\n",
      "Image for 'parts' saved to 'extracted_images/parts.jpg'.\n",
      "Image for 'ventricles' saved to 'extracted_images/ventricles.jpg'.\n",
      "Coherence: 0.0000, Similarity: 0.0496\n",
      "Chunk Result: Bad\n",
      "\n",
      "Processing Chunk 2: 'It is the most important part of the human body. I...'\n",
      "Extracted Keywords: ['part', 'body', 'heart']\n",
      "Image for 'part' saved to 'extracted_images/part.jpg'.\n",
      "Image for 'body' saved to 'extracted_images/body.jpg'.\n",
      "Image for 'heart' saved to 'extracted_images/heart.jpg'.\n",
      "Coherence: 0.0000, Similarity: 0.1173\n",
      "Chunk Result: Bad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Configuration ---\n",
    "CHUNK_SIZE_T = 5\n",
    "SSIM_THRESHOLD_TC = 0.75\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "FEATURE_EXTRACTION_LAYER = 'layer4'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TARGET_SIZE = (224, 224)  # Target size for image resizing\n",
    "\n",
    "# Download necessary NLTK data (run once)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    \"\"\"Extract top nouns from text.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    nouns = [word for word, tag in pos_tags if tag.startswith('NN') and word.isalnum() and word not in stop_words]\n",
    "    return [word for word, _ in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "\n",
    "def scrape_image_from_web(keyword, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"Scrape an image from Google Images based on a keyword.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    search_url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "        \n",
    "        if not img_tags or len(img_tags) < 2:\n",
    "            print(f\"No suitable images found for '{keyword}'.\")\n",
    "            return None\n",
    "        \n",
    "        img_url = img_tags[1].get('src') or img_tags[1].get('data-src')\n",
    "        if not img_url:\n",
    "            print(f\"Could not find valid image URL for '{keyword}'.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            img_response = requests.get(img_url, stream=True, timeout=10)\n",
    "            img_response.raise_for_status()\n",
    "            image = Image.open(BytesIO(img_response.content)).convert('RGB').resize(TARGET_SIZE)\n",
    "            filename = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            image.save(filepath, \"JPEG\")\n",
    "            print(f\"Image for '{keyword}' saved to '{filepath}'.\")\n",
    "            return filepath\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading or processing image for '{keyword}': {e}\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during search for '{keyword}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_ssim(image1, image2):\n",
    "    \"\"\"Calculate Structural Similarity Index (SSIM) between two images.\"\"\"\n",
    "    if image1 is None or image2 is None:\n",
    "        return 0.0\n",
    "    \n",
    "    img1_gray = image1.convert('L')\n",
    "    img2_gray = image2.convert('L')\n",
    "    array1 = np.array(img1_gray)\n",
    "    array2 = np.array(img2_gray)\n",
    "    \n",
    "    return ssim(array1, array2, data_range=array2.max() - array2.min())\n",
    "\n",
    "\n",
    "def get_image_features(image, model, layer_name, transform):\n",
    "    \"\"\"Extract features from an image using a pre-trained model.\"\"\"\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    image_t = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    features = None\n",
    "    \n",
    "    def hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output.flatten(start_dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    layer = getattr(model, layer_name)\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    model(image_t)\n",
    "    handle.remove()\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(features1, features2):\n",
    "    \"\"\"Calculate cosine similarity between two feature vectors.\"\"\"\n",
    "    if features1 is None or features2 is None:\n",
    "        return 0.0\n",
    "    \n",
    "    features1_tensor = torch.tensor(features1).float()\n",
    "    features2_tensor = torch.tensor(features2).float()\n",
    "    \n",
    "    return cosine_similarity(features1_tensor, features2_tensor).item()\n",
    "\n",
    "\n",
    "# --- Processing Functions ---\n",
    "def assess_chunk_coherence(image_paths):\n",
    "    \"\"\"Assess coherence of a chunk based on SSIM.\"\"\"\n",
    "    if len(image_paths) < 2:\n",
    "        return 1.0\n",
    "    \n",
    "    images = [Image.open(path).convert('RGB').resize(TARGET_SIZE) for path in image_paths]\n",
    "    \n",
    "    ssim_scores = [\n",
    "        calculate_ssim(images[i], images[i + 1]) for i in range(len(images) - 1)\n",
    "    ]\n",
    "    \n",
    "    coherence_score = sum(1 for score in ssim_scores if score > SSIM_THRESHOLD_TC) / len(ssim_scores)\n",
    "    \n",
    "    return coherence_score\n",
    "\n",
    "\n",
    "def assess_chunk_similarity(image_paths, model, transform):\n",
    "    \"\"\"Assess similarity of a chunk based on cosine similarity.\"\"\"\n",
    "    if len(image_paths) < 2:\n",
    "        return 1.0\n",
    "    \n",
    "    images = [Image.open(path).convert('RGB').resize(TARGET_SIZE) for path in image_paths]\n",
    "    \n",
    "    features_list = [get_image_features(img, model, FEATURE_EXTRACTION_LAYER, transform) for img in images]\n",
    "    \n",
    "    similarities = [\n",
    "        calculate_cosine_similarity(features_list[i], features_list[i + 1]) for i in range(len(features_list) - 1)\n",
    "    ]\n",
    "    \n",
    "    return np.mean(similarities)\n",
    "\n",
    "\n",
    "def process_chunks(chunks):\n",
    "    \"\"\"Process text chunks to extract images and evaluate coherence/similarity.\"\"\"\n",
    "    \n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(DEVICE).eval()\n",
    "    transform = weights.transforms()\n",
    "    \n",
    "    all_image_paths = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_nouns(chunk)\n",
    "            print(f\"\\nProcessing Chunk {i+1}: '{chunk[:50]}...'\")\n",
    "            print(f\"Extracted Keywords: {keywords}\")\n",
    "            \n",
    "            chunk_image_paths = []\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                filepath = scrape_image_from_web(keyword)\n",
    "                if filepath:\n",
    "                    chunk_image_paths.append(filepath)\n",
    "                    all_image_paths.append(filepath)\n",
    "            \n",
    "            # Evaluate chunk coherence and similarity\n",
    "            coherence_score = assess_chunk_coherence(chunk_image_paths)\n",
    "            similarity_score = assess_chunk_similarity(chunk_image_paths, model, transform)\n",
    "            \n",
    "            print(f\"Coherence: {coherence_score:.4f}, Similarity: {similarity_score:.4f}\")\n",
    "            \n",
    "            # Final evaluation of results\n",
    "            status = \"Good\" if coherence_score >= SSIM_THRESHOLD_TC and similarity_score >= SIMILARITY_THRESHOLD else \"Bad\"\n",
    "            print(f\"Chunk Result: {status}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"\\nSkipping empty chunk {i+1}.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    text_input = \"\"\"\n",
    "There is a heart. The heart has 4 parts. Heart has ventricles and arteries that supply blood in and out of the heart.\n",
    "It is the most important part of the human body. If the heart stops everything else stops.\n",
    "\"\"\"\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks_to_process = text_splitter.split_text(text_input.strip())\n",
    "    \n",
    "    process_chunks(chunks_to_process)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHUNKS AND EXTRACTED NOUNS ===\n",
      "\n",
      "CHUNK 1: let’s talk about the circulatory system. The heart plays a central role in pumping blood throughout the body. Its basic structure includes the right\n",
      "  Extracted Nouns: ['talk', 'circulatory', 'system']\n",
      "\n",
      "CHUNK 2: structure includes the right cardiac muscle, which pushes deoxygenated blood toward the lungs, and the left cardiac muscle, which pumps oxygenated\n",
      "  Extracted Nouns: ['muscle', 'structure', 'cardiac']\n",
      "\n",
      "CHUNK 3: which pumps oxygenated blood to the body. Blood enters through the inferior vena cava, travels to the lungs via the pulmonary artery, and returns\n",
      "  Extracted Nouns: ['blood', 'pumps', 'body']\n",
      "\n",
      "CHUNK 4: pulmonary artery, and returns through the veins once it’s oxygenated. Finally, the aorta carries this oxygen-rich blood to all parts of the body.\n",
      "  Extracted Nouns: ['artery', 'returns', 'veins']\n",
      "\n",
      "=== PROCESSING INDIVIDUAL CHUNKS ===\n",
      "\n",
      "CHUNK 1 Comparing: talk vs system\n",
      "[CHUNK 1 (Internal)]\n",
      "  SSIM: 0.0981\n",
      "  Cosine Similarity: 0.0565\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 2 Comparing: muscle vs cardiac\n",
      "[CHUNK 2 (Internal)]\n",
      "  SSIM: 0.2580\n",
      "  Cosine Similarity: 0.2276\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 3 Comparing: blood vs body\n",
      "[CHUNK 3 (Internal)]\n",
      "  SSIM: 0.2745\n",
      "  Cosine Similarity: 0.0385\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 4 Comparing: artery vs veins\n",
      "[CHUNK 4 (Internal)]\n",
      "  SSIM: 0.3369\n",
      "  Cosine Similarity: 0.2119\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "[FUSED CHUNK (Representation)]\n",
      "  SSIM: 1.0000\n",
      "  Cosine Similarity: 1.0000\n",
      "========================================\n",
      "\n",
      "=== EVALUATING CHUNKS AGAINST FUSED REPRESENTATION ===\n",
      "\n",
      "CHUNK 1 Keywords: ['talk', 'circulatory', 'system']\n",
      "[CHUNK 1 (Start vs Fused)]\n",
      "  SSIM: 0.4776\n",
      "  Cosine Similarity: 0.0215\n",
      "----------------------------------------\n",
      "[CHUNK 1 (End vs Fused)]\n",
      "  SSIM: 0.1834\n",
      "  Cosine Similarity: 0.0158\n",
      "----------------------------------------\n",
      "CHUNK 2 Keywords: ['muscle', 'structure', 'cardiac']\n",
      "[CHUNK 2 (Start vs Fused)]\n",
      "  SSIM: 0.4200\n",
      "  Cosine Similarity: 0.0694\n",
      "----------------------------------------\n",
      "[CHUNK 2 (End vs Fused)]\n",
      "  SSIM: 0.4335\n",
      "  Cosine Similarity: 0.0301\n",
      "----------------------------------------\n",
      "CHUNK 3 Keywords: ['blood', 'pumps', 'body']\n",
      "[CHUNK 3 (Start vs Fused)]\n",
      "  SSIM: 0.3466\n",
      "  Cosine Similarity: 0.0324\n",
      "----------------------------------------\n",
      "[CHUNK 3 (End vs Fused)]\n",
      "  SSIM: 0.5496\n",
      "  Cosine Similarity: 0.0269\n",
      "----------------------------------------\n",
      "CHUNK 4 Keywords: ['artery', 'returns', 'veins']\n",
      "[CHUNK 4 (Start vs Fused)]\n",
      "  SSIM: 0.4719\n",
      "  Cosine Similarity: 0.0306\n",
      "----------------------------------------\n",
      "[CHUNK 4 (End vs Fused)]\n",
      "  SSIM: 0.4473\n",
      "  Cosine Similarity: 0.0274\n",
      "----------------------------------------\n",
      "\n",
      "=== FUSED CHUNK EVALUATION ===\n",
      "Average SSIM to Fused: 0.4162\n",
      "Average Cosine Similarity to Fused: 0.0317\n",
      "Fused Chunk Status: BAD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- Config ---\n",
    "CHUNK_SIZE_T = 150\n",
    "CHUNK_OVERLAP = 30\n",
    "SSIM_THRESHOLD = 0.75\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "TARGET_SIZE = (224, 224)\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "FEATURE_LAYER = 'layer4'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Init ---\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    nouns = [word for (word, tag) in tagged if tag.startswith(\"NN\") and word not in stop_words and word.isalnum()]\n",
    "    return [word for word, _ in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "def get_or_scrape_image(keyword):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    fname = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "    fpath = os.path.join(OUTPUT_DIR, fname)\n",
    "    if os.path.exists(fpath):\n",
    "        return fpath\n",
    "    try:\n",
    "        url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        img_url = soup.find_all('img')[1].get('src')\n",
    "        img_data = requests.get(img_url, timeout=10).content\n",
    "        img = Image.open(BytesIO(img_data)).convert('RGB').resize(TARGET_SIZE)\n",
    "        img.save(fpath)\n",
    "        return fpath\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(np.array(img1.convert('L')), np.array(img2.convert('L')), data_range=255)\n",
    "\n",
    "def get_image_features(image, model, transform):\n",
    "    image_t = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    features = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        features.append(output.flatten(start_dim=1).detach().cpu().numpy())\n",
    "\n",
    "    handle = model._modules.get(FEATURE_LAYER).register_forward_hook(hook)\n",
    "    model(image_t)\n",
    "    handle.remove()\n",
    "    return features[0]\n",
    "\n",
    "def calculate_cosine_similarity(f1, f2):\n",
    "    t1 = torch.tensor(f1).float()\n",
    "    t2 = torch.tensor(f2).float()\n",
    "    return cosine_similarity(t1, t2).item()\n",
    "\n",
    "def fuse_chunks(image_paths):\n",
    "    images = [Image.open(p).resize(TARGET_SIZE).convert('L') for p in image_paths]\n",
    "    arrays = [np.array(im) for im in images]\n",
    "    avg_array = np.mean(arrays, axis=0).astype(np.uint8)\n",
    "    return Image.fromarray(avg_array).convert('RGB')\n",
    "\n",
    "def print_similarity(title, ssim_score, cosine_score, border=False):\n",
    "    print(f\"[{title}]\")\n",
    "    print(f\"  SSIM: {ssim_score:.4f}\")\n",
    "    print(f\"  Cosine Similarity: {cosine_score:.4f}\")\n",
    "    print(\"-\" * 40 if not border else \"=\" * 40)\n",
    "\n",
    "# --- Main Processing ---\n",
    "def main():\n",
    "    text = \"\"\"let’s talk about the circulatory system. The heart plays a central role in pumping blood throughout the body. Its basic structure includes the right cardiac muscle, which pushes deoxygenated blood toward the lungs, and the left cardiac muscle, which pumps oxygenated blood to the body. Blood enters through the inferior vena cava, travels to the lungs via the pulmonary artery, and returns through the veins once it’s oxygenated. Finally, the aorta carries this oxygen-rich blood to all parts of the body.\"\"\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE_T, chunk_overlap=CHUNK_OVERLAP)\n",
    "    chunks = splitter.split_text(text.strip())\n",
    "\n",
    "    print(\"=== CHUNKS AND EXTRACTED NOUNS ===\")\n",
    "    chunk_keywords = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        keywords = extract_nouns(chunk)\n",
    "        chunk_keywords.append(keywords)\n",
    "        print(f\"\\nCHUNK {i + 1}: {chunk}\")\n",
    "        print(f\"  Extracted Nouns: {keywords}\")\n",
    "\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(DEVICE).eval()\n",
    "    transform = weights.transforms()\n",
    "\n",
    "    chunk_images = []\n",
    "    chunk_representations = []\n",
    "\n",
    "    print(\"\\n=== PROCESSING INDIVIDUAL CHUNKS ===\\n\")\n",
    "    for idx, (chunk, keywords) in enumerate(zip(chunks, chunk_keywords)):\n",
    "        image_paths = [get_or_scrape_image(k) for k in keywords if k]\n",
    "        image_paths = [p for p in image_paths if p]\n",
    "\n",
    "        if len(image_paths) < 1:\n",
    "            print(f\"CHUNK {idx + 1}: Insufficient images to process.\")\n",
    "            continue\n",
    "\n",
    "        images = [Image.open(p).resize(TARGET_SIZE).convert('RGB') for p in image_paths]\n",
    "        features = [get_image_features(img, model, transform) for img in images]\n",
    "\n",
    "        if images:\n",
    "            chunk_representations.append((images[0], images[-1], features[0], features[-1]))\n",
    "            chunk_images.append(image_paths)\n",
    "\n",
    "            if len(images) >= 2:\n",
    "                print(f\"CHUNK {idx + 1} Comparing: {keywords[0]} vs {keywords[-1]}\")\n",
    "                ssim_score = calculate_ssim(images[0], images[-1])\n",
    "                cosine_score = calculate_cosine_similarity(features[0], features[-1])\n",
    "                status = \"GOOD\" if ssim_score >= SSIM_THRESHOLD and cosine_score >= SIMILARITY_THRESHOLD else \"BAD\"\n",
    "                print_similarity(f\"CHUNK {idx + 1} (Internal)\", ssim_score, cosine_score)\n",
    "                print(f\"  Chunk Comparison Status: {status}\")\n",
    "                print(\"-\" * 40)\n",
    "            else:\n",
    "                print_similarity(f\"CHUNK {idx + 1} (Single Image)\", 1.0, 1.0)\n",
    "                print(f\"  Chunk Comparison Status: GOOD\")\n",
    "                print(\"-\" * 40)\n",
    "\n",
    "    all_images_flat = [item for sublist in chunk_images for item in sublist]\n",
    "    fused_img = None\n",
    "    fused_features = None\n",
    "\n",
    "    if all_images_flat:\n",
    "        fused_img = fuse_chunks(all_images_flat)\n",
    "        fused_features = get_image_features(fused_img, model, transform)\n",
    "        print_similarity(\"FUSED CHUNK (Representation)\", 1.0, 1.0, border=True)\n",
    "\n",
    "        print(\"\\n=== EVALUATING CHUNKS AGAINST FUSED REPRESENTATION ===\\n\")\n",
    "        for idx, (img_start, img_end, feat_start, feat_end) in enumerate(chunk_representations):\n",
    "            print(f\"CHUNK {idx + 1} Keywords: {chunk_keywords[idx]}\")\n",
    "            ssim_start = calculate_ssim(img_start, fused_img)\n",
    "            cosine_start = calculate_cosine_similarity(feat_start, fused_features)\n",
    "            print_similarity(f\"CHUNK {idx + 1} (Start vs Fused)\", ssim_start, cosine_start)\n",
    "\n",
    "            ssim_end = calculate_ssim(img_end, fused_img)\n",
    "            cosine_end = calculate_cosine_similarity(feat_end, fused_features)\n",
    "            print_similarity(f\"CHUNK {idx + 1} (End vs Fused)\", ssim_end, cosine_end)\n",
    "\n",
    "        if chunk_representations:\n",
    "            avg_ssim_to_fused_start = np.mean([calculate_ssim(rep[0], fused_img) for rep in chunk_representations])\n",
    "            avg_cosine_to_fused_start = np.mean([calculate_cosine_similarity(rep[2], fused_features) for rep in chunk_representations])\n",
    "            avg_ssim_to_fused_end = np.mean([calculate_ssim(rep[1], fused_img) for rep in chunk_representations])\n",
    "            avg_cosine_to_fused_end = np.mean([calculate_cosine_similarity(rep[3], fused_features) for rep in chunk_representations])\n",
    "\n",
    "            overall_ssim_to_fused = (avg_ssim_to_fused_start + avg_ssim_to_fused_end) / 2\n",
    "            overall_cosine_to_fused = (avg_cosine_to_fused_start + avg_cosine_to_fused_end) / 2\n",
    "\n",
    "            fused_status = \"GOOD\" if overall_ssim_to_fused >= SSIM_THRESHOLD and overall_cosine_to_fused >= SIMILARITY_THRESHOLD else \"BAD\"\n",
    "            print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "            print(f\"Average SSIM to Fused: {overall_ssim_to_fused:.4f}\")\n",
    "            print(f\"Average Cosine Similarity to Fused: {overall_cosine_to_fused:.4f}\")\n",
    "            print(f\"Fused Chunk Status: {fused_status}\")\n",
    "        else:\n",
    "            print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "            print(\"No chunks were processed to evaluate the fused chunk.\")\n",
    "    else:\n",
    "        print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "        print(\"No images were available to create a fused chunk.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHUNKS AND EXTRACTED NOUNS ===\n",
      "\n",
      "CHUNK 1: let’s talk about the circulatory system. The heart plays a central role in pumping blood throughout the body. Its basic structure includes the right\n",
      "  Extracted Nouns: ['talk', 'circulatory', 'system']\n",
      "\n",
      "CHUNK 2: structure includes the right cardiac muscle, which pushes deoxygenated blood toward the lungs, and the left cardiac muscle, which pumps oxygenated\n",
      "  Extracted Nouns: ['muscle', 'structure', 'cardiac']\n",
      "\n",
      "CHUNK 3: which pumps oxygenated blood to the body. Blood enters through the inferior vena cava, travels to the lungs via the pulmonary artery, and returns\n",
      "  Extracted Nouns: ['blood', 'pumps', 'body']\n",
      "\n",
      "CHUNK 4: pulmonary artery, and returns through the veins once it’s oxygenated. Finally, the aorta carries this oxygen-rich blood to all parts of the body.\n",
      "  Extracted Nouns: ['artery', 'returns', 'veins']\n",
      "\n",
      "=== PROCESSING INDIVIDUAL CHUNKS ===\n",
      "\n",
      "CHUNK 1 Comparing: talk vs system\n",
      "[CHUNK 1 (Internal)]\n",
      "  SSIM: 0.0981\n",
      "  Cosine Similarity: 0.0529\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 2 Comparing: muscle vs cardiac\n",
      "[CHUNK 2 (Internal)]\n",
      "  SSIM: 0.2580\n",
      "  Cosine Similarity: 0.0479\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 3 Comparing: blood vs body\n",
      "[CHUNK 3 (Internal)]\n",
      "  SSIM: 0.2745\n",
      "  Cosine Similarity: 0.0356\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "CHUNK 4 Comparing: artery vs veins\n",
      "[CHUNK 4 (Internal)]\n",
      "  SSIM: 0.3369\n",
      "  Cosine Similarity: 0.0302\n",
      "----------------------------------------\n",
      "  Chunk Comparison Status: BAD\n",
      "----------------------------------------\n",
      "[FUSED CHUNK (Representation)]\n",
      "  SSIM: 1.0000\n",
      "  Cosine Similarity: 1.0000\n",
      "========================================\n",
      "\n",
      "=== EVALUATING CHUNKS AGAINST FUSED REPRESENTATION ===\n",
      "\n",
      "CHUNK 1 Keywords: ['talk', 'circulatory', 'system']\n",
      "[CHUNK 1 (Start vs Fused)]\n",
      "  SSIM: 0.4776\n",
      "  Cosine Similarity: 0.0398\n",
      "----------------------------------------\n",
      "[CHUNK 1 (End vs Fused)]\n",
      "  SSIM: 0.1834\n",
      "  Cosine Similarity: 0.0342\n",
      "----------------------------------------\n",
      "CHUNK 2 Keywords: ['muscle', 'structure', 'cardiac']\n",
      "[CHUNK 2 (Start vs Fused)]\n",
      "  SSIM: 0.4200\n",
      "  Cosine Similarity: 0.0509\n",
      "----------------------------------------\n",
      "[CHUNK 2 (End vs Fused)]\n",
      "  SSIM: 0.4335\n",
      "  Cosine Similarity: 0.0371\n",
      "----------------------------------------\n",
      "CHUNK 3 Keywords: ['blood', 'pumps', 'body']\n",
      "[CHUNK 3 (Start vs Fused)]\n",
      "  SSIM: 0.3466\n",
      "  Cosine Similarity: 0.0598\n",
      "----------------------------------------\n",
      "[CHUNK 3 (End vs Fused)]\n",
      "  SSIM: 0.5496\n",
      "  Cosine Similarity: 0.0333\n",
      "----------------------------------------\n",
      "CHUNK 4 Keywords: ['artery', 'returns', 'veins']\n",
      "[CHUNK 4 (Start vs Fused)]\n",
      "  SSIM: 0.4719\n",
      "  Cosine Similarity: 0.0311\n",
      "----------------------------------------\n",
      "[CHUNK 4 (End vs Fused)]\n",
      "  SSIM: 0.4473\n",
      "  Cosine Similarity: 0.0252\n",
      "----------------------------------------\n",
      "\n",
      "=== FUSED CHUNK EVALUATION ===\n",
      "Average SSIM to Fused: 0.4162\n",
      "Average Cosine Similarity to Fused: 0.0389\n",
      "Fused Chunk Status: BAD\n",
      "Files already downloaded and verified\n",
      "\n",
      "=== CIFAR-10 Evaluation ===\n",
      "Accuracy: 0.7648\n",
      "Precision: 0.7699\n",
      "Recall: 0.7657\n",
      "F1 Score: 0.7637\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Config ---\n",
    "CHUNK_SIZE_T = 150\n",
    "CHUNK_OVERLAP = 30\n",
    "SSIM_THRESHOLD = 0.75\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "TARGET_SIZE = (224, 224)\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "FEATURE_LAYER = 'layer4'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CIFAR10_BATCH_SIZE = 32  # Reduced batch size\n",
    "CIFAR10_LR = 0.001\n",
    "CIFAR10_EPOCHS = 1\n",
    "CIFAR10_ROOT = \"./data\"\n",
    "\n",
    "# --- Init ---\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    nouns = [word for (word, tag) in tagged if tag.startswith(\"NN\") and word not in stop_words and word.isalnum()]\n",
    "    return [word for word, _ in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "def get_or_scrape_image(keyword):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    fname = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "    fpath = os.path.join(OUTPUT_DIR, fname)\n",
    "    if os.path.exists(fpath):\n",
    "        return fpath\n",
    "    try:\n",
    "        url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        img_url = soup.find_all('img')[1].get('src')\n",
    "        img_data = requests.get(img_url, timeout=10).content\n",
    "        img = Image.open(BytesIO(img_data)).convert('RGB').resize(TARGET_SIZE)\n",
    "        img.save(fpath)\n",
    "        return fpath\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(np.array(img1.convert('L')), np.array(img2.convert('L')), data_range=255)\n",
    "\n",
    "def get_image_features(image, model, transform):\n",
    "    image_t = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    features = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        features.append(output.flatten(start_dim=1).detach().cpu().numpy())\n",
    "\n",
    "    handle = model._modules.get(FEATURE_LAYER).register_forward_hook(hook)\n",
    "    model(image_t)\n",
    "    handle.remove()\n",
    "    return features[0]\n",
    "\n",
    "def calculate_cosine_similarity(f1, f2):\n",
    "    t1 = torch.tensor(f1).float()\n",
    "    t2 = torch.tensor(f2).float()\n",
    "    return cosine_similarity(t1, t2).item()\n",
    "\n",
    "def fuse_chunks(image_paths):\n",
    "    images = [Image.open(p).resize(TARGET_SIZE).convert('L') for p in image_paths]\n",
    "    arrays = [np.array(im) for im in images]\n",
    "    avg_array = np.mean(arrays, axis=0).astype(np.uint8)\n",
    "    return Image.fromarray(avg_array).convert('RGB')\n",
    "\n",
    "def print_similarity(title, ssim_score, cosine_score, border=False):\n",
    "    print(f\"[{title}]\")\n",
    "    print(f\"  SSIM: {ssim_score:.4f}\")\n",
    "    print(f\"  Cosine Similarity: {cosine_score:.4f}\")\n",
    "    print(\"-\" * 40 if not border else \"=\" * 40)\n",
    "\n",
    "# --- CIFAR-10 Training and Evaluation ---\n",
    "def train_and_evaluate_cifar10(model):\n",
    "    # Load CIFAR-10 dataset with separate transforms\n",
    "    cifar10_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset = CIFAR10(root=CIFAR10_ROOT, train=True, download=True, transform=cifar10_transform)\n",
    "\n",
    "    # Verify dataset is not empty\n",
    "    if len(dataset) == 0:\n",
    "        print(\"CIFAR-10 dataset is empty or not correctly loaded.\")\n",
    "        return\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CIFAR10_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CIFAR10_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=CIFAR10_LR)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(CIFAR10_EPOCHS):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(actual_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(actual_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(actual_labels, predicted_labels, average='macro')\n",
    "\n",
    "    print(\"\\n=== CIFAR-10 Evaluation ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# --- Main Processing ---\n",
    "def main():\n",
    "    text = \"\"\"let’s talk about the circulatory system. The heart plays a central role in pumping blood throughout the body. Its basic structure includes the right cardiac muscle, which pushes deoxygenated blood toward the lungs, and the left cardiac muscle, which pumps oxygenated blood to the body. Blood enters through the inferior vena cava, travels to the lungs via the pulmonary artery, and returns through the veins once it’s oxygenated. Finally, the aorta carries this oxygen-rich blood to all parts of the body.\"\"\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE_T, chunk_overlap=CHUNK_OVERLAP)\n",
    "    chunks = splitter.split_text(text.strip())\n",
    "\n",
    "    print(\"=== CHUNKS AND EXTRACTED NOUNS ===\")\n",
    "    chunk_keywords = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        keywords = extract_nouns(chunk)\n",
    "        chunk_keywords.append(keywords)\n",
    "        print(f\"\\nCHUNK {i + 1}: {chunk}\")\n",
    "        print(f\"  Extracted Nouns: {keywords}\")\n",
    "\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(DEVICE)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    transform = weights.transforms()\n",
    "\n",
    "    chunk_images = []\n",
    "    chunk_representations = []\n",
    "\n",
    "    print(\"\\n=== PROCESSING INDIVIDUAL CHUNKS ===\\n\")\n",
    "    for idx, (chunk, keywords) in enumerate(zip(chunks, chunk_keywords)):\n",
    "        image_paths = [get_or_scrape_image(k) for k in keywords if k]\n",
    "        image_paths = [p for p in image_paths if p]\n",
    "\n",
    "        if len(image_paths) < 1:\n",
    "            print(f\"CHUNK {idx + 1}: Insufficient images to process.\")\n",
    "            continue\n",
    "\n",
    "        images = [Image.open(p).resize(TARGET_SIZE).convert('RGB') for p in image_paths]\n",
    "        features = [get_image_features(img, model, transform) for img in images]\n",
    "\n",
    "        if images:\n",
    "            chunk_representations.append((images[0], images[-1], features[0], features[-1]))\n",
    "            chunk_images.append(image_paths)\n",
    "\n",
    "            if len(images) >= 2:\n",
    "                print(f\"CHUNK {idx + 1} Comparing: {keywords[0]} vs {keywords[-1]}\")\n",
    "                ssim_score = calculate_ssim(images[0], images[-1])\n",
    "                cosine_score = calculate_cosine_similarity(features[0], features[-1])\n",
    "                status = \"GOOD\" if ssim_score >= SSIM_THRESHOLD and cosine_score >= SIMILARITY_THRESHOLD else \"BAD\"\n",
    "                print_similarity(f\"CHUNK {idx + 1} (Internal)\", ssim_score, cosine_score)\n",
    "                print(f\"  Chunk Comparison Status: {status}\")\n",
    "                print(\"-\" * 40)\n",
    "            else:\n",
    "                print_similarity(f\"CHUNK {idx + 1} (Single Image)\", 1.0, 1.0)\n",
    "                print(f\"  Chunk Comparison Status: GOOD\")\n",
    "                print(\"-\" * 40)\n",
    "\n",
    "    all_images_flat = [item for sublist in chunk_images for item in sublist]\n",
    "    fused_img = None\n",
    "    fused_features = None\n",
    "\n",
    "    if all_images_flat:\n",
    "        fused_img = fuse_chunks(all_images_flat)\n",
    "        fused_features = get_image_features(fused_img, model, transform)\n",
    "        print_similarity(\"FUSED CHUNK (Representation)\", 1.0, 1.0, border=True)\n",
    "\n",
    "        print(\"\\n=== EVALUATING CHUNKS AGAINST FUSED REPRESENTATION ===\\n\")\n",
    "        for idx, (img_start, img_end, feat_start, feat_end) in enumerate(chunk_representations):\n",
    "            print(f\"CHUNK {idx + 1} Keywords: {chunk_keywords[idx]}\")\n",
    "            ssim_start = calculate_ssim(img_start, fused_img)\n",
    "            cosine_start = calculate_cosine_similarity(feat_start, fused_features)\n",
    "            print_similarity(f\"CHUNK {idx + 1} (Start vs Fused)\", ssim_start, cosine_start)\n",
    "\n",
    "            ssim_end = calculate_ssim(img_end, fused_img)\n",
    "            cosine_end = calculate_cosine_similarity(feat_end, fused_features)\n",
    "            print_similarity(f\"CHUNK {idx + 1} (End vs Fused)\", ssim_end, cosine_end)\n",
    "\n",
    "        if chunk_representations:\n",
    "            avg_ssim_to_fused_start = np.mean([calculate_ssim(rep[0], fused_img) for rep in chunk_representations])\n",
    "            avg_cosine_to_fused_start = np.mean([calculate_cosine_similarity(rep[2], fused_features) for rep in chunk_representations])\n",
    "            avg_ssim_to_fused_end = np.mean([calculate_ssim(rep[1], fused_img) for rep in chunk_representations])\n",
    "            avg_cosine_to_fused_end = np.mean([calculate_cosine_similarity(rep[3], fused_features) for rep in chunk_representations])\n",
    "\n",
    "            overall_ssim_to_fused = (avg_ssim_to_fused_start + avg_ssim_to_fused_end) / 2\n",
    "            overall_cosine_to_fused = (avg_cosine_to_fused_start + avg_cosine_to_fused_end) / 2\n",
    "            fused_status = \"GOOD\" if overall_ssim_to_fused >= SSIM_THRESHOLD and overall_cosine_to_fused >= SIMILARITY_THRESHOLD else \"BAD\"\n",
    "            print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "            print(f\"Average SSIM to Fused: {overall_ssim_to_fused:.4f}\")\n",
    "            print(f\"Average Cosine Similarity to Fused: {overall_cosine_to_fused:.4f}\")\n",
    "            print(f\"Fused Chunk Status: {fused_status}\")\n",
    "        else:\n",
    "            print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "            print(\"No chunks were processed to evaluate the fused chunk.\")\n",
    "    else:\n",
    "        print(\"\\n=== FUSED CHUNK EVALUATION ===\")\n",
    "        print(\"No images were available to create a fused chunk.\")\n",
    "\n",
    "    # Train and evaluate CIFAR-10\n",
    "    train_and_evaluate_cifar10(model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
